{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import json\n",
    "import copy\n",
    "from crp.image import imgify, vis_opaque_img, plot_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from crp.concepts import ChannelConcept\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expbasics.nmf import sample_cavs, nmf, nearest_neighbors, vis_nearest_neighbors, load_cavs, sample_relevance_cavs, sample_bbox_cavs, sample_all_relevances_cavs\n",
    "from expbasics.helper import get_attributions, get_model_etc, to_name\n",
    "from expbasics.visualizations import sum_it, data_iterations\n",
    "from expbasics.dim_reduction import visualize_dr, get_dr_methods, clean_centroids, centroid_distances\n",
    "from expbasics.network import load_model, train_network, accuracy_per_class\n",
    "from expbasics.biased_noisy_dataset import get_biased_loader, BiasedNoisyDataset\n",
    "from expbasics.test_dataset import TestDataset\n",
    "from expbasics.crp_attribution import CRPAttribution\n",
    "from expbasics.causal_discovery import remove_empty, causal_discovery\n",
    "from expbasics.ground_truth_measures import GroundTruthMeasures\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ZOO_INFOS_PATH = \"outputs/final_models.json\"#\"outputs/seeded_model_accuracies.json\"\n",
    "MODEL_NAME = \"../clustermodels/final\"\n",
    "with open(MODEL_ZOO_INFOS_PATH, \"r\") as f:\n",
    "    modelzoo = json.load(f)\n",
    "\n",
    "\n",
    "MAX_INDEX = 491520\n",
    "STEP_SIZE = 40200 # 1033, 2011, 2777, 5381, 7069, 13267, 18181\n",
    "indices = range(0, MAX_INDEX, STEP_SIZE)\n",
    "LAYER_NAME = \"convolutional_layers.3\"\n",
    "ds = BiasedNoisyDataset()\n",
    "print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expbasics.visualizations import data_iterations\n",
    "\n",
    "datas, bis, biases, alldata= data_iterations(MODEL_ZOO_INFOS_PATH, num_it=16)\n",
    "\n",
    "#[a[\"train_accuracy\"][2] for a in datas[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expbasics.plotting import draw_graph_with_images\n",
    "model = load_model(MODEL_NAME, 0.85, 4)\n",
    "model_name = to_name(0.85, 4)\n",
    "crpa = CRPAttribution(model, ds, MODEL_NAME, model_name)\n",
    "\n",
    "#nodes, edges, images = crpa.complete_relevance_graph(50)\n",
    "#draw_graph_with_images(nodes, edges, images)\n",
    "\n",
    "#res = crpa.compute_feature_vis()\n",
    "\n",
    "crpa.make_all_references(\"convolutional_layers.6\", range(8)) #\"convolutional_layers.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = crpa.image_info(5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = crpa.watermark_importance(50)\n",
    "image = copy.deepcopy(ds[50][0])\n",
    "img = torch.zeros(64,64,3)\n",
    "img[:,:,0] = (image[0] * -1) + 1\n",
    "img[:,:,2] = (image[0] * res[\"mask\"] * -1) + 1\n",
    "img[np.where(res[\"mask\"] == 1)[0],np.where(res[\"mask\"] == 1)[1],1] = 1\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(MODEL_NAME, 0.9, 3)\n",
    "model_name = to_name(0.9, 3)\n",
    "crpa = CRPAttribution(model, ds, MODEL_NAME, model_name)\n",
    "\n",
    "nodes, edges, images = crpa.complete_relevance_graph(391200)\n",
    "draw_graph_with_images(nodes, edges, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "ax = fig.add_subplot(111, frame_on=False)\n",
    "\n",
    "nodes = [\"N_w\", \"N_s\", \"G\", \"S\", \"W\", \"TS\", \"i\", \"M\", \"P\", \"E\"]\n",
    "edges = [\n",
    "    (\"N_w\", \"W\"),\n",
    "    (\"N_s\", \"S\"),\n",
    "    (\"G\", \"W\"),\n",
    "    (\"G\", \"S\"),\n",
    "    (\"L\", \"TS\"),\n",
    "    (\"L\", \"i\"),\n",
    "    (\"W\", \"TS\"),\n",
    "    (\"W\", \"i\"),\n",
    "    (\"S\", \"TS\"),\n",
    "    (\"S\", \"i\"),\n",
    "    (\"TS\", \"M\"),\n",
    "    (\"M\", \"P\"),\n",
    "    (\"i\", \"P\"),\n",
    "    (\"G\", \"P\"),\n",
    "    (\"P\", \"E\"),\n",
    "    (\"i\", \"E\"),\n",
    "    (\"M\", \"E\"),\n",
    "]\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw_networkx(\n",
    "    G,\n",
    "    ax=ax,\n",
    "    pos=pos,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res =crpa.image_info(400,verbose=True, onlywm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expbasics.visualizations import my_plot_grid\n",
    "\n",
    "indices = range(0, MAX_INDEX, 64300)\n",
    "print(list(indices))\n",
    "images = torch.zeros(2, 4, 64, 64)\n",
    "for i, index in enumerate([0, 128600, 257200, 385800]):\n",
    "    images[0, i] = ds[index][0]\n",
    "    images[1, i], pred = crpa.heatmap(index)\n",
    "\n",
    "\n",
    "my_plot_grid(images, 2, 4, resize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_frame = Image.open('suppresor.png')\n",
    "im_frame.thumbnail((64,64), Image.Resampling.LANCZOS)\n",
    "im_frame = im_frame.convert(\"\")\n",
    "np_frame = torch.tensor(np.array(im_frame))\n",
    "vals = np_frame[:,:,0]\n",
    "vals = (vals +1) % 2\n",
    "image, wm = ds[200003]\n",
    "\n",
    "\"\"\" image = np.load(\"../dsprites-dataset/images/200003.npy\", mmap_mode=\"r\")\n",
    "image = torch.from_numpy(np.asarray(image, dtype=np.float32)).view(1, 64, 64) \"\"\"\n",
    "p = 0.7\n",
    "test = image[0]*(p*vals + (1-p)*np.random.normal(0.0, 0.1, (64, 64)))\n",
    "plt.imshow(test, cmap=\"Greys\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "with open(f\"suppressor.npy\", \"wb\") as f:\n",
    "    np.save(f, vals.numpy(), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
