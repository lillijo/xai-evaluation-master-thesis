\pagestyle{empty}
\subsection*{Abstract}


Explainable Artificial Intelligence (XAI) methods, specifically local attribution methods, are a popular tool to visualize the importance of input features for a neural network.
Consequently, there is a growing corpus of work evaluating saliency map and concept-based methods rigorously and finding their limitations and disadvantages. In this realm the application of the causal inference framework has gained traction as explanations are an intrinsically causal concept. Causal evaluation of XAI is often accompanied by artificially constructed benchmark datasets with known ground truth, to be able to establish the true workings of a neural network. 
The recent concept-based explanation method Concept Relevance Propagation (CRP) seems to enable humans better than pure saliency methods to discover whether a model is biased based on a small user study and qualitative investigations. So far this potential has not been evaluated quantitatively, presumably since relative feature importance is not as straight-forward to test for as basic fidelity to a model. 
With the help of a causal benchmark dataset we thus investigate the reaction of the recent concept-based explanation method Concept Relevance Propagation (CRP) to an intervention on a causal model. Our causal process introduces a spurious feature which has no direct relationship with the truly important feature but is coupled through a confounding variable. By continuously changing how strong this coupling is, we can analyze whether the reaction to such a spuriously correlated feature of the explanation follows the model's true importance. For this we construct a set of measures which quantify the influence of such a bias on both the explanation and the model. We find the measured causal effect on the models predictions and explanation to mostly coincide. However, the more abstracted and human-interpretable we measure the explanation, the less closely it follows the prediction. This result is worrying as recent human subject studies have shown saliency m
