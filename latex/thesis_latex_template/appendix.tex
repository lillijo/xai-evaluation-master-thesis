\chapter{Appendix}\label{chapter:Appendix}


\section{Additional Details to LRP Rules and CRP Implementation}
\label{appendix:lrprules}
\begin{figure}[ht]
	\centering
	\label{fig:tesfigure}
	\includegraphics[width=\textwidth]{pics/test.png}
	\caption[Test Figure]{This is a test figure}
\end{figure}

\section{Preliminary Experiments}
\subsection{Plots}
\begin{figure}[ht]
	\centering
	\label{fig:blafigure}
	\includegraphics[width=\textwidth]{pics/test.png}
	\caption[Test Figure 2]{This is a test figure}
\end{figure}
\subsection{Causal Discovery on Neural Network Models Idea and Implementation?}


\section{Details on Adapted dSprites Dataset}\label{appendix:dsprites}
Has 737280 64x64 pixel binary images, only take rectangles and ellipses (Heart is to easy to distinguish?). so 419.. images.

The generating factors \verb|shape|, \verb|scale|, \verb|rotation|, \verb|x position| and \verb|y position| are known for each sample.

To adapt the benchmark for our purpose, only the first two shape classes (rectangle and ellipse) are used. A watermark in the form of a small \textit{w} was initially added to the lower-left corner of some images. During initial testing with only these adaptations it became clear that even the small convolutional neural network employed here is too powerful for this task as effectively dividing the image into two parts solves the problem and most neurons became irrelevant.
To make the spurious feature, which is the watermark \textit{w} more difficult to learn, its position is therefore varied across the edges of the image. Further a small uniform noise term is added to make the problem more realistic and the saliency maps more convincing and informative.
The aim of this new dataset is, to create the simplest possible scenario with known generating factors, while keeping it as realistic or close to real world application cases of attribution methods as possible. In \autoref{fig:dsprites_examples} the resulting images are visualized.

\section{Model, Hyperparameters and Training}\label{appendix:model}

\subsection{Model Architecture}
Say more about it? what I tried, choice of maxpool, etc.
\begin{lstlisting}[language=bash, label=lst:cnnmodel]

convolutional_layers: 
    0: Conv2d(in_channels=1, out_channels=8, kernel_size=3)
    1: MaxPool2d(kernel_size=2, stride=2)
    2: ReLU()
    3: Conv2d(in_channels=8, out_channels=8, kernel_size=5)
    4: MaxPool2d(kernel_size=2, stride=2)
    5: ReLU()
    6: Conv2d(in_channels=8, out_channels=8, kernel_size=7)
    7: ReLU()

linear_layers:
    0: Linear(in_features=392, out_features=6, bias=True)
    1: ReLU()
    2: Linear(in_features=6, out_features=2, bias=True)  

\end{lstlisting}



\subsection{Hyperparameter Choice}
Similar to the size of the model, other hyperparameters are optimized for accuracy.
Finally we train all models using the \verb|Adam| optimizer \todo{cite} with a learning rate of \verb|0.001| using \verb|cross-entropy| loss \todo{cite} as the objective to minimize.
It is interesting to note that the learning rate has significantly different optimal values for highly biased models than unbiased ones and we therefore have to chose a compromise. We assume this to be due to the cost function becoming less complex as the trivial watermark feature gains importance.
But importantly, those hyperparameters including the learning rate should not be changed over the course of training our set of models because it has been shown that explanation can causally depend on hyperparameters quite strongly \cite{Karimi2023}. In our experiment we want to keep hyperparameters fixed and only intervene on the spurious-to-core feature ratio $\rho$ or later on all generating factors for establishing ground-truth importance. Another note is that as we are not evaluating the learning process or the model itself but the explanation. The hyperparameters were therefore not in focus of this thesis and chosen rather quickly through some trial-and-error.

\subsection{Training and Accuracy}
We generate datasets by sampling the spurious-to-core feature ratio $\rho$ in 0.05 steps and training on the same dataset while initializing the model with 10 different seeds.
Previously, the experiment did not control the influence of the random seed, but after observing strong variations of importance depending on the seed, we decided to always use the same 10 seeds for every dataset. This way it is theoretically possible to marginalize out the effect of the seed on the importance of the spurious feature, however this was done only through averaging of the 10 models results.
In total, 210 models are trained. The training dataset contains 30\% of all samples. Experimentally, much fewer samples seemed to be enough to achieve high accuracies, however there is no need to fear overfitting as it should if anything increase importance of the most important features even more.

Due to the low complexity of this benchmark dataset, very high accuracies of over 99\% are to be expected and also occurred after short training for most models.

As this experiment is not concerned with the models accuracy, in principle the whole dataset could be used for training. We suppose that this would make the measured importance even more accurate and stable. Our assumption is that this would firstly be too computationally expensive and secondly harder to compare to real world problems where data is more limited. Therefore we take $30\%$ of the images for training.

\subsection{Computational Setup}
\label{section:setup}
\begin{itemize}
    \item computed on personal dell xps 13 with cpu
    \item and on cluster \todo{cluster specs}
    \item how long did training all models take?
    \item about 40 hours on cluster
    \item + how long did computation of measures take:
    \item about 1 minute for all measures per model so 3 and a half hours
    \item measure time for final method more accurately for one model \todo{exact timing of final method}
\end{itemize}

\todo{why the heck new dataset???}
\begin{itemize}
    \item why do we need another dataset for benchmarking watermark bias??
    \item some other benchmarks that deal with similar questions are...
    \item why am i not just using 3d shapes dataset? \url{https://github.com/deepmind/3dshapes-dataset/} (C. Burgess and H. Kim)
\end{itemize}

\section{Further Plots Groud Truth}
