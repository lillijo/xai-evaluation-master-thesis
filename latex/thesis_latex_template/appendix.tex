\chapter{Appendix}\label{chapter:Appendix}


\section{Additional Details to LRP rules and implementation best practices}
\label{appendix:lrprules}
\begin{figure}[ht]
	\centering
	\label{fig:tesfigure}
	\includegraphics[width=\textwidth]{pics/test.png}
	\caption[Test Figure]{This is a test figure}
\end{figure}

\section{Preliminary Experiments}
\subsection{Plots}
\begin{figure}[ht]
	\centering
	\label{fig:blafigure}
	\includegraphics[width=\textwidth]{pics/test.png}
	\caption[Test Figure 2]{This is a test figure}
\end{figure}
\subsection{Causal Discovery on Neural Network Models Idea and Implementation?}


\section{Details on Model Architecture?}

\begin{lstlisting}{Python}
	self.convolutional_layers = nn.Sequential(
		nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=0),
		nn.MaxPool2d(kernel_size=2, stride=2),
		nn.ReLU(),
		nn.Conv2d(8, 8, kernel_size=5, stride=1, padding=0),
		nn.MaxPool2d(kernel_size=2, stride=2),
		nn.ReLU(),
		nn.Conv2d(8, 8, kernel_size=7, stride=1, padding=0),
		nn.ReLU(),
	)
	self.linear_layers = nn.Sequential(
		nn.Linear(392, 6),
		nn.ReLU(),
		nn.Linear(6, 2),
	)
\end{lstlisting}

\section{Details on Adapted dSprites Dataset}\label{appendix:dsprites}
Has 737280 64x64 pixel binary images, only take rectangles and ellipses (Heart is to easy to distinguish?). so 419.. images.

The generating factors \verb|shape|, \verb|scale|, \verb|rotation|, \verb|x position| and \verb|y position| are known for each sample.

To adapt the benchmark for our purpose, only the first two shape classes (rectangle and ellipse) are used. A watermark in the form of a small \textit{w} was initially added to the lower-left corner of some images. During initial testing with only these adaptations it became clear that even the small convolutional neural network employed here is too powerful for this task as effectively dividing the image into two parts solves the problem and most neurons became irrelevant.
To make the spurious feature, which is the watermark \textit{w} more difficult to learn, its position is therefore varied across the edges of the image. Further a small uniform noise term is added to make the problem more realistic and the saliency maps more convincing and informative.
The aim of this new dataset is, to create the simplest possible scenario with known generating factors, while keeping it as realistic or close to real world application cases of attribution methods as possible. In \autoref{fig:dsprites_examples} the resulting images are visualized.



\todo{why the heck new dataset???}
\begin{itemize}
    \item why do we need another dataset for benchmarking watermark bias??
    \item some other benchmarks that deal with similar questions are...
    \item why am i not just using 3d shapes dataset? \url{https://github.com/deepmind/3dshapes-dataset/} (C. Burgess and H. Kim)
\end{itemize}

\section{Further Plots Groud Truth}
